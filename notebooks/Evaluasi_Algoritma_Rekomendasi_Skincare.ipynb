{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üß™ Evaluasi Algoritma Rekomendasi Skincare\n",
    "## Panduan Langkah demi Langkah\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Tujuan Evaluasi**\n",
    "Notebook ini akan memandu Anda melalui proses evaluasi algoritma rekomendasi skincare **langkah demi langkah**, dari persiapan data hingga analisis hasil akhir.\n",
    "\n",
    "### üìã **Langkah-langkah yang akan dilakukan:**\n",
    "1. **Setup Environment** - Install library dan import dependencies\n",
    "2. **Persiapan Data** - Generate dataset untuk testing\n",
    "3. **Implementasi Algoritma** - Build sistem rekomendasi\n",
    "4. **Ground Truth Generation** - Buat data referensi untuk evaluasi\n",
    "5. **Eksekusi Evaluasi** - Jalankan pengujian dengan berbagai nilai K\n",
    "6. **Analisis Hasil** - Interpretasi metrik dan visualisasi\n",
    "7. **Kesimpulan** - Rekomendasi untuk implementasi\n",
    "\n",
    "### üìä **Metrik yang akan dievaluasi:**\n",
    "- **Precision@K**: Seberapa akurat rekomendasi yang diberikan\n",
    "- **Recall@K**: Seberapa lengkap rekomendasi menangkap produk relevan\n",
    "- **F1-Score@K**: Keseimbangan antara precision dan recall\n",
    "- **NDCG@K**: Kualitas ranking rekomendasi\n",
    "- **MAP**: Mean Average Precision untuk evaluasi keseluruhan\n",
    "\n",
    "---\n",
    "**Mari mulai evaluasi! üöÄ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1_header"
   },
   "source": [
    "## üîß Langkah 1: Setup Environment\n",
    "\n",
    "Pertama, kita akan menginstall dan mengimport semua library yang diperlukan untuk evaluasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step1_install"
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "print(\"üîß Installing required libraries...\")\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn scipy\n",
    "print(\"‚úÖ Installation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step1_imports"
   },
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "print(\"üìö Importing libraries...\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"üìä Environment ready for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1_checkpoint"
   },
   "source": [
    "### ‚úÖ **Checkpoint 1**: Environment Setup Complete\n",
    "Jika tidak ada error di atas, environment sudah siap. Mari lanjut ke langkah berikutnya!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2_header"
   },
   "source": [
    "## üìä Langkah 2: Persiapan Data\n",
    "\n",
    "Sekarang kita akan membuat dataset sintetis untuk testing. Dataset ini akan mensimulasikan data pengguna dan produk skincare yang realistis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step2_generate_products"
   },
   "outputs": [],
   "source": [
    "# Generate synthetic product dataset\n",
    "print(\"üß¥ Generating synthetic skincare products dataset...\")\n",
    "\n",
    "np.random.seed(42)  # For reproducible results\n",
    "\n",
    "# Product categories and attributes\n",
    "categories = ['Cleanser', 'Moisturizer', 'Serum', 'Sunscreen', 'Toner']\n",
    "skin_types = ['Normal', 'Oily', 'Dry', 'Combination', 'Sensitive']\n",
    "concerns = ['Acne', 'Anti-aging', 'Brightening', 'Hydration', 'Oil Control']\n",
    "price_ranges = ['Budget', 'Mid-range', 'Premium']\n",
    "\n",
    "# Generate 50 products\n",
    "products_data = []\n",
    "for i in range(1, 51):\n",
    "    category = np.random.choice(categories)\n",
    "    skin_type = np.random.choice(skin_types)\n",
    "    concern = np.random.choice(concerns)\n",
    "    price_range = np.random.choice(price_ranges)\n",
    "    \n",
    "    # Create realistic product names\n",
    "    brand_names = ['GlowSkin', 'PureCare', 'NaturalBeauty', 'SkinLab', 'BeautyEssence']\n",
    "    brand = np.random.choice(brand_names)\n",
    "    product_name = f\"{brand} {concern} {category}\"\n",
    "    \n",
    "    # Generate price based on range\n",
    "    if price_range == 'Budget':\n",
    "        price = np.random.randint(50000, 150000)\n",
    "    elif price_range == 'Mid-range':\n",
    "        price = np.random.randint(150000, 400000)\n",
    "    else:  # Premium\n",
    "        price = np.random.randint(400000, 800000)\n",
    "    \n",
    "    # Create description\n",
    "    description = f\"{category} untuk kulit {skin_type.lower()} dengan fokus {concern.lower()}\"\n",
    "    \n",
    "    products_data.append({\n",
    "        'product_id': i,\n",
    "        'nama_produk': product_name,\n",
    "        'kategori': category,\n",
    "        'jenis_kulit': skin_type,\n",
    "        'masalah_kulit': concern,\n",
    "        'harga': price,\n",
    "        'range_harga': price_range,\n",
    "        'deskripsi': description\n",
    "    })\n",
    "\n",
    "products_df = pd.DataFrame(products_data)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(products_df)} products\")\n",
    "print(\"\\nüìã Sample products:\")\n",
    "display(products_df.head())\n",
    "\n",
    "print(\"\\nüìä Product distribution:\")\n",
    "print(f\"Categories: {products_df['kategori'].value_counts().to_dict()}\")\n",
    "print(f\"Skin Types: {products_df['jenis_kulit'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step2_generate_users"
   },
   "outputs": [],
   "source": [
    "# Generate synthetic user dataset\n",
    "print(\"üë• Generating synthetic user profiles...\")\n",
    "\n",
    "users_data = []\n",
    "for i in range(1, 21):  # 20 users for testing\n",
    "    kondisi_kulit = np.random.choice(skin_types)\n",
    "    masalah_utama = np.random.choice(concerns)\n",
    "    preferensi_produk = np.random.choice(categories)\n",
    "    budget = np.random.choice(price_ranges)\n",
    "    usia = np.random.randint(18, 45)\n",
    "    \n",
    "    users_data.append({\n",
    "        'user_id': i,\n",
    "        'kondisi_kulit': kondisi_kulit,\n",
    "        'masalah_utama': masalah_utama,\n",
    "        'preferensi_produk': preferensi_produk,\n",
    "        'budget': budget,\n",
    "        'usia': usia\n",
    "    })\n",
    "\n",
    "users_df = pd.DataFrame(users_data)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(users_df)} user profiles\")\n",
    "print(\"\\nüìã Sample users:\")\n",
    "display(users_df.head())\n",
    "\n",
    "print(\"\\nüìä User distribution:\")\n",
    "print(f\"Skin conditions: {users_df['kondisi_kulit'].value_counts().to_dict()}\")\n",
    "print(f\"Main concerns: {users_df['masalah_utama'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2_checkpoint"
   },
   "source": [
    "### ‚úÖ **Checkpoint 2**: Data Generation Complete\n",
    "Dataset berhasil dibuat! Kita memiliki:\n",
    "- **50 produk skincare** dengan berbagai kategori dan karakteristik\n",
    "- **20 profil pengguna** dengan preferensi yang beragam\n",
    "\n",
    "Data ini akan digunakan untuk menguji algoritma rekomendasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3_header"
   },
   "source": [
    "## ü§ñ Langkah 3: Implementasi Algoritma Rekomendasi\n",
    "\n",
    "Sekarang kita akan mengimplementasikan sistem rekomendasi hybrid CBF+KNN langkah demi langkah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step3_cbf_implementation"
   },
   "outputs": [],
   "source": [
    "# Step 3a: Implement Content-Based Filtering\n",
    "print(\"üîç Implementing Content-Based Filtering...\")\n",
    "\n",
    "class ContentBasedFilter:\n",
    "    def __init__(self, products_df):\n",
    "        self.products_df = products_df\n",
    "        self.tfidf_vectorizer = None\n",
    "        self.product_features = None\n",
    "        self._prepare_features()\n",
    "    \n",
    "    def _prepare_features(self):\n",
    "        \"\"\"Prepare product features for TF-IDF vectorization\"\"\"\n",
    "        # Combine all text features\n",
    "        self.products_df['combined_features'] = (\n",
    "            self.products_df['kategori'] + ' ' +\n",
    "            self.products_df['jenis_kulit'] + ' ' +\n",
    "            self.products_df['masalah_kulit'] + ' ' +\n",
    "            self.products_df['range_harga'] + ' ' +\n",
    "            self.products_df['deskripsi']\n",
    "        )\n",
    "        \n",
    "        # Create TF-IDF vectors\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(\n",
    "            stop_words=None,\n",
    "            lowercase=True,\n",
    "            max_features=1000\n",
    "        )\n",
    "        \n",
    "        self.product_features = self.tfidf_vectorizer.fit_transform(\n",
    "            self.products_df['combined_features']\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ TF-IDF features prepared: {self.product_features.shape}\")\n",
    "    \n",
    "    def create_user_profile(self, user_data):\n",
    "        \"\"\"Create user profile from user preferences\"\"\"\n",
    "        user_text = (\n",
    "            f\"{user_data['preferensi_produk']} \"\n",
    "            f\"{user_data['kondisi_kulit']} \"\n",
    "            f\"{user_data['masalah_utama']} \"\n",
    "            f\"{user_data['budget']}\"\n",
    "        )\n",
    "        \n",
    "        user_vector = self.tfidf_vectorizer.transform([user_text])\n",
    "        return user_vector\n",
    "    \n",
    "    def calculate_similarity(self, user_profile):\n",
    "        \"\"\"Calculate cosine similarity between user and products\"\"\"\n",
    "        similarities = cosine_similarity(user_profile, self.product_features)\n",
    "        return similarities.flatten()\n",
    "\n",
    "# Initialize CBF\n",
    "cbf = ContentBasedFilter(products_df)\n",
    "print(\"‚úÖ Content-Based Filtering implemented successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step3_test_cbf"
   },
   "outputs": [],
   "source": [
    "# Step 3b: Test Content-Based Filtering\n",
    "print(\"üß™ Testing Content-Based Filtering...\")\n",
    "\n",
    "# Test with first user\n",
    "test_user = users_df.iloc[0].to_dict()\n",
    "print(f\"\\nüë§ Test User Profile:\")\n",
    "print(f\"   Skin Type: {test_user['kondisi_kulit']}\")\n",
    "print(f\"   Main Concern: {test_user['masalah_utama']}\")\n",
    "print(f\"   Preferred Product: {test_user['preferensi_produk']}\")\n",
    "print(f\"   Budget: {test_user['budget']}\")\n",
    "\n",
    "# Create user profile and calculate similarities\n",
    "user_profile = cbf.create_user_profile(test_user)\n",
    "similarities = cbf.calculate_similarity(user_profile)\n",
    "\n",
    "# Get top 5 recommendations\n",
    "top_indices = np.argsort(similarities)[::-1][:5]\n",
    "\n",
    "print(f\"\\nüéØ Top 5 CBF Recommendations:\")\n",
    "for i, idx in enumerate(top_indices):\n",
    "    product = products_df.iloc[idx]\n",
    "    similarity_score = similarities[idx]\n",
    "    print(f\"   {i+1}. {product['nama_produk']} (Similarity: {similarity_score:.3f})\")\n",
    "    print(f\"      Category: {product['kategori']}, Skin Type: {product['jenis_kulit']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Content-Based Filtering test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step3_knn_implementation"
   },
   "outputs": [],
   "source": [
    "# Step 3c: Implement K-Nearest Neighbors Enhancement\n",
    "print(\"üîó Implementing K-Nearest Neighbors enhancement...\")\n",
    "\n",
    "class KNNEnhancer:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "    \n",
    "    def find_k_nearest_neighbors(self, target_user_idx, users_df):\n",
    "        \"\"\"Find K nearest neighbors based on user similarity\"\"\"\n",
    "        # Simple similarity based on shared preferences\n",
    "        target_user = users_df.iloc[target_user_idx]\n",
    "        similarities = []\n",
    "        \n",
    "        for idx, user in users_df.iterrows():\n",
    "            if idx == target_user_idx:\n",
    "                continue\n",
    "            \n",
    "            # Calculate similarity score\n",
    "            similarity = 0\n",
    "            if user['kondisi_kulit'] == target_user['kondisi_kulit']:\n",
    "                similarity += 1\n",
    "            if user['masalah_utama'] == target_user['masalah_utama']:\n",
    "                similarity += 1\n",
    "            if user['preferensi_produk'] == target_user['preferensi_produk']:\n",
    "                similarity += 1\n",
    "            if user['budget'] == target_user['budget']:\n",
    "                similarity += 1\n",
    "            \n",
    "            similarities.append((idx, similarity))\n",
    "        \n",
    "        # Sort by similarity and get top K\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        k_neighbors = [idx for idx, _ in similarities[:self.k]]\n",
    "        \n",
    "        return k_neighbors\n",
    "    \n",
    "    def calculate_knn_boost(self, content_similarities, k_neighbors, k):\n",
    "        \"\"\"Calculate KNN boost factors\"\"\"\n",
    "        boosted_scores = content_similarities.copy()\n",
    "        \n",
    "        # Parameters based on K value\n",
    "        if k <= 3:\n",
    "            position_multiplier = 1.8\n",
    "            exclusivity_bonus = 0.3\n",
    "            exclusion_penalty = 0.4\n",
    "        elif k <= 7:\n",
    "            position_multiplier = 1.5\n",
    "            exclusivity_bonus = 0.2\n",
    "            exclusion_penalty = 0.3\n",
    "        else:\n",
    "            position_multiplier = 1.3\n",
    "            exclusivity_bonus = 0.1\n",
    "            exclusion_penalty = 0.2\n",
    "        \n",
    "        # Apply boosts and penalties\n",
    "        for i, score in enumerate(content_similarities):\n",
    "            if i < len(k_neighbors):  # Inside K neighbors\n",
    "                position_boost = position_multiplier * (1 - i / len(k_neighbors))\n",
    "                exclusivity_boost = exclusivity_bonus\n",
    "                boosted_scores[i] = score * position_boost + exclusivity_boost\n",
    "            else:  # Outside K neighbors\n",
    "                penalty = exclusion_penalty * (score ** 2)\n",
    "                boosted_scores[i] = max(0, score - penalty)\n",
    "        \n",
    "        return boosted_scores\n",
    "\n",
    "print(\"‚úÖ K-Nearest Neighbors enhancement implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step3_hybrid_system"
   },
   "outputs": [],
   "source": [
    "# Step 3d: Create Hybrid Recommendation System\n",
    "print(\"üîÑ Creating Hybrid CBF+KNN System...\")\n",
    "\n",
    "class HybridRecommendationSystem:\n",
    "    def __init__(self, products_df, users_df):\n",
    "        self.products_df = products_df\n",
    "        self.users_df = users_df\n",
    "        self.cbf = ContentBasedFilter(products_df)\n",
    "    \n",
    "    def get_recommendations(self, user_id, k=5, top_n=10):\n",
    "        \"\"\"Get hybrid recommendations for a user\"\"\"\n",
    "        # Get user data\n",
    "        user_idx = user_id - 1  # Convert to 0-based index\n",
    "        user_data = self.users_df.iloc[user_idx].to_dict()\n",
    "        \n",
    "        # Step 1: Content-Based Filtering\n",
    "        user_profile = self.cbf.create_user_profile(user_data)\n",
    "        content_similarities = self.cbf.calculate_similarity(user_profile)\n",
    "        \n",
    "        # Step 2: K-Nearest Neighbors Enhancement\n",
    "        knn_enhancer = KNNEnhancer(k=k)\n",
    "        k_neighbors = knn_enhancer.find_k_nearest_neighbors(user_idx, self.users_df)\n",
    "        \n",
    "        # Step 3: Apply KNN boost\n",
    "        final_scores = knn_enhancer.calculate_knn_boost(\n",
    "            content_similarities, k_neighbors, k\n",
    "        )\n",
    "        \n",
    "        # Step 4: Get top recommendations\n",
    "        top_indices = np.argsort(final_scores)[::-1][:top_n]\n",
    "        \n",
    "        recommendations = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            product = self.products_df.iloc[idx]\n",
    "            boost_factor = final_scores[idx] / content_similarities[idx] if content_similarities[idx] > 0 else 1.0\n",
    "            \n",
    "            recommendations.append({\n",
    "                'rank': i + 1,\n",
    "                'product_id': product['product_id'],\n",
    "                'nama_produk': product['nama_produk'],\n",
    "                'content_similarity': content_similarities[idx],\n",
    "                'knn_score': final_scores[idx],\n",
    "                'boost_factor': boost_factor\n",
    "            })\n",
    "        \n",
    "        return recommendations, k_neighbors\n",
    "\n",
    "# Initialize hybrid system\n",
    "hybrid_system = HybridRecommendationSystem(products_df, users_df)\n",
    "print(\"‚úÖ Hybrid Recommendation System created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3_checkpoint"
   },
   "source": [
    "### ‚úÖ **Checkpoint 3**: Algorithm Implementation Complete\n",
    "Sistem rekomendasi hybrid berhasil diimplementasikan! Komponen yang telah dibuat:\n",
    "- ‚úÖ **Content-Based Filtering** dengan TF-IDF\n",
    "- ‚úÖ **K-Nearest Neighbors** enhancement\n",
    "- ‚úÖ **Hybrid System** yang menggabungkan keduanya\n",
    "\n",
    "Mari lanjut untuk menguji sistem ini!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4_header"
   },
   "source": [
    "## üéØ Langkah 4: Test Sistem Rekomendasi\n",
    "\n",
    "Sekarang kita akan menguji sistem rekomendasi dengan beberapa pengguna dan nilai K yang berbeda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step4_test_single_user"
   },
   "outputs": [],
   "source": [
    "# Step 4a: Test with single user and different K values\n",
    "print(\"üß™ Testing Hybrid System with Different K Values...\")\n",
    "\n",
    "test_user_id = 1\n",
    "test_user_data = users_df[users_df['user_id'] == test_user_id].iloc[0]\n",
    "\n",
    "print(f\"\\nüë§ Testing with User {test_user_id}:\")\n",
    "print(f\"   Skin Type: {test_user_data['kondisi_kulit']}\")\n",
    "print(f\"   Main Concern: {test_user_data['masalah_utama']}\")\n",
    "print(f\"   Preferred Product: {test_user_data['preferensi_produk']}\")\n",
    "print(f\"   Budget: {test_user_data['budget']}\")\n",
    "\n",
    "# Test with different K values\n",
    "k_values = [3, 5, 7]\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\nüî∏ Results for K={k}:\")\n",
    "    recommendations, neighbors = hybrid_system.get_recommendations(test_user_id, k=k, top_n=5)\n",
    "    \n",
    "    print(f\"   K-Nearest Neighbors: {neighbors}\")\n",
    "    print(f\"   Top 5 Recommendations:\")\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        print(f\"     {rec['rank']}. {rec['nama_produk']}\")\n",
    "        print(f\"        Content Sim: {rec['content_similarity']:.3f}, \"\n",
    "              f\"KNN Score: {rec['knn_score']:.3f}, \"\n",
    "              f\"Boost: {rec['boost_factor']:.2f}x\")\n",
    "\n",
    "print(\"\\n‚úÖ Single user testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4_checkpoint"
   },
   "source": [
    "### ‚úÖ **Checkpoint 4**: System Testing Complete\n",
    "Sistem rekomendasi berhasil diuji! Anda dapat melihat bagaimana nilai K yang berbeda menghasilkan rekomendasi yang berbeda.\n",
    "\n",
    "Sekarang mari kita buat ground truth untuk evaluasi yang lebih sistematis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5_header"
   },
   "source": [
    "## üìã Langkah 5: Generate Ground Truth\n",
    "\n",
    "Untuk evaluasi yang akurat, kita perlu membuat \"ground truth\" - data referensi yang menunjukkan produk mana yang benar-benar relevan untuk setiap pengguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step5_ground_truth"
   },
   "outputs": [],
   "source": [
    "# Step 5: Generate Ground Truth Data\n",
    "print(\"üìã Generating Ground Truth for Evaluation...\")\n",
    "\n",
    "def generate_ground_truth(users_df, products_df):\n",
    "    \"\"\"Generate ground truth based on user-product matching logic\"\"\"\n",
    "    ground_truth = {}\n",
    "    \n",
    "    for _, user in users_df.iterrows():\n",
    "        user_id = user['user_id']\n",
    "        relevant_products = []\n",
    "        \n",
    "        for _, product in products_df.iterrows():\n",
    "            relevance_score = 0\n",
    "            \n",
    "            # Exact matches get high relevance\n",
    "            if product['jenis_kulit'] == user['kondisi_kulit']:\n",
    "                relevance_score += 2\n",
    "            if product['masalah_kulit'] == user['masalah_utama']:\n",
    "                relevance_score += 2\n",
    "            if product['kategori'] == user['preferensi_produk']:\n",
    "                relevance_score += 1\n",
    "            if product['range_harga'] == user['budget']:\n",
    "                relevance_score += 1\n",
    "            \n",
    "            # Products with score >= 3 are considered relevant\n",
    "            if relevance_score >= 3:\n",
    "                relevant_products.append(product['product_id'])\n",
    "        \n",
    "        ground_truth[user_id] = relevant_products\n",
    "    \n",
    "    return ground_truth\n",
    "\n",
    "# Generate ground truth\n",
    "ground_truth = generate_ground_truth(users_df, products_df)\n",
    "\n",
    "print(f\"‚úÖ Ground truth generated for {len(ground_truth)} users\")\n",
    "\n",
    "# Show sample ground truth\n",
    "print(\"\\nüìä Sample Ground Truth:\")\n",
    "for user_id in list(ground_truth.keys())[:3]:\n",
    "    relevant_count = len(ground_truth[user_id])\n",
    "    print(f\"   User {user_id}: {relevant_count} relevant products\")\n",
    "    if relevant_count > 0:\n",
    "        sample_products = ground_truth[user_id][:3]\n",
    "        for pid in sample_products:\n",
    "            product_name = products_df[products_df['product_id'] == pid]['nama_produk'].iloc[0]\n",
    "            print(f\"     - {product_name}\")\n",
    "\n",
    "# Statistics\n",
    "total_relevant = sum(len(products) for products in ground_truth.values())\n",
    "avg_relevant = total_relevant / len(ground_truth)\n",
    "print(f\"\\nüìà Ground Truth Statistics:\")\n",
    "print(f\"   Total relevant pairs: {total_relevant}\")\n",
    "print(f\"   Average relevant products per user: {avg_relevant:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5_checkpoint"
   },
   "source": [
    "### ‚úÖ **Checkpoint 5**: Ground Truth Generation Complete\n",
    "Ground truth berhasil dibuat! Setiap pengguna memiliki daftar produk yang dianggap relevan berdasarkan kecocokan profil.\n",
    "\n",
    "Sekarang kita siap untuk melakukan evaluasi sistematis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6_header"
   },
   "source": [
    "## üìä Langkah 6: Implementasi Metrik Evaluasi\n",
    "\n",
    "Sekarang kita akan mengimplementasikan metrik evaluasi untuk mengukur kinerja algoritma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step6_metrics"
   },
   "outputs": [],
   "source": [
    "# Step 6: Implement Evaluation Metrics\n",
    "print(\"üìä Implementing Evaluation Metrics...\")\n",
    "\n",
    "class RecommendationEvaluator:\n",
    "    def __init__(self, ground_truth):\n",
    "        self.ground_truth = ground_truth\n",
    "    \n",
    "    def precision_at_k(self, recommended_items, relevant_items, k):\n",
    "        \"\"\"Calculate Precision@K\"\"\"\n",
    "        if k == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        recommended_k = recommended_items[:k]\n",
    "        relevant_recommended = len(set(recommended_k) & set(relevant_items))\n",
    "        return relevant_recommended / k\n",
    "    \n",
    "    def recall_at_k(self, recommended_items, relevant_items, k):\n",
    "        \"\"\"Calculate Recall@K\"\"\"\n",
    "        if len(relevant_items) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        recommended_k = recommended_items[:k]\n",
    "        relevant_recommended = len(set(recommended_k) & set(relevant_items))\n",
    "        return relevant_recommended / len(relevant_items)\n",
    "    \n",
    "    def f1_score_at_k(self, recommended_items, relevant_items, k):\n",
    "        \"\"\"Calculate F1-Score@K\"\"\"\n",
    "        precision = self.precision_at_k(recommended_items, relevant_items, k)\n",
    "        recall = self.recall_at_k(recommended_items, relevant_items, k)\n",
    "        \n",
    "        if precision + recall == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    def ndcg_at_k(self, recommended_items, relevant_items, k):\n",
    "        \"\"\"Calculate NDCG@K\"\"\"\n",
    "        def dcg_at_k(relevances, k):\n",
    "            relevances = relevances[:k]\n",
    "            return sum(rel / np.log2(i + 2) for i, rel in enumerate(relevances))\n",
    "        \n",
    "        # Binary relevance (1 if relevant, 0 if not)\n",
    "        relevances = [1 if item in relevant_items else 0 for item in recommended_items[:k]]\n",
    "        \n",
    "        if sum(relevances) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Ideal DCG (all relevant items at top)\n",
    "        ideal_relevances = [1] * min(len(relevant_items), k) + [0] * max(0, k - len(relevant_items))\n",
    "        \n",
    "        dcg = dcg_at_k(relevances, k)\n",
    "        idcg = dcg_at_k(ideal_relevances, k)\n",
    "        \n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "    \n",
    "    def mean_average_precision(self, all_recommendations):\n",
    "        \"\"\"Calculate Mean Average Precision (MAP)\"\"\"\n",
    "        total_ap = 0\n",
    "        num_users = 0\n",
    "        \n",
    "        for user_id, recommendations in all_recommendations.items():\n",
    "            relevant_items = self.ground_truth.get(user_id, [])\n",
    "            if len(relevant_items) == 0:\n",
    "                continue\n",
    "            \n",
    "            recommended_items = [rec['product_id'] for rec in recommendations]\n",
    "            \n",
    "            # Calculate Average Precision for this user\n",
    "            ap = 0\n",
    "            relevant_found = 0\n",
    "            \n",
    "            for i, item in enumerate(recommended_items):\n",
    "                if item in relevant_items:\n",
    "                    relevant_found += 1\n",
    "                    precision_at_i = relevant_found / (i + 1)\n",
    "                    ap += precision_at_i\n",
    "            \n",
    "            if relevant_found > 0:\n",
    "                ap /= len(relevant_items)\n",
    "            \n",
    "            total_ap += ap\n",
    "            num_users += 1\n",
    "        \n",
    "        return total_ap / num_users if num_users > 0 else 0.0\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = RecommendationEvaluator(ground_truth)\n",
    "print(\"‚úÖ Evaluation metrics implemented successfully!\")\n",
    "\n",
    "# Test metrics with sample data\n",
    "print(\"\\nüß™ Testing metrics with sample data...\")\n",
    "sample_recommended = [1, 2, 3, 4, 5]\n",
    "sample_relevant = [1, 3, 7, 9]\n",
    "\n",
    "precision_5 = evaluator.precision_at_k(sample_recommended, sample_relevant, 5)\n",
    "recall_5 = evaluator.recall_at_k(sample_recommended, sample_relevant, 5)\n",
    "f1_5 = evaluator.f1_score_at_k(sample_recommended, sample_relevant, 5)\n",
    "ndcg_5 = evaluator.ndcg_at_k(sample_recommended, sample_relevant, 5)\n",
    "\n",
    "print(f\"   Sample Precision@5: {precision_5:.3f}\")\n",
    "print(f\"   Sample Recall@5: {recall_5:.3f}\")\n",
    "print(f\"   Sample F1@5: {f1_5:.3f}\")\n",
    "print(f\"   Sample NDCG@5: {ndcg_5:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6_checkpoint"
   },
   "source": [
    "### ‚úÖ **Checkpoint 6**: Evaluation Metrics Ready\n",
    "Semua metrik evaluasi berhasil diimplementasikan:\n",
    "- ‚úÖ **Precision@K**: Mengukur akurasi rekomendasi\n",
    "- ‚úÖ **Recall@K**: Mengukur coverage produk relevan\n",
    "- ‚úÖ **F1-Score@K**: Keseimbangan precision dan recall\n",
    "- ‚úÖ **NDCG@K**: Kualitas ranking\n",
    "- ‚úÖ **MAP**: Mean Average Precision\n",
    "\n",
    "Sekarang mari kita jalankan evaluasi lengkap!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7_header"
   },
   "source": [
    "## üöÄ Langkah 7: Eksekusi Evaluasi Lengkap\n",
    "\n",
    "Sekarang kita akan menjalankan evaluasi lengkap untuk semua pengguna dengan berbagai nilai K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step7_full_evaluation"
   },
   "outputs": [],
   "source": [
    "# Step 7: Run Full Evaluation\n",
    "print(\"üöÄ Running Full Evaluation...\")\n",
    "print(\"This may take a moment...\")\n",
    "\n",
    "def run_evaluation(k_values, top_k_list):\n",
    "    \"\"\"Run evaluation for different K values\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        print(f\"\\nüîÑ Evaluating K={k}...\")\n",
    "        \n",
    "        # Generate recommendations for all users\n",
    "        all_recommendations = {}\n",
    "        \n",
    "        for user_id in users_df['user_id']:\n",
    "            recommendations, _ = hybrid_system.get_recommendations(user_id, k=k, top_n=10)\n",
    "            all_recommendations[user_id] = recommendations\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'precision': {},\n",
    "            'recall': {},\n",
    "            'f1_score': {},\n",
    "            'ndcg': {}\n",
    "        }\n",
    "        \n",
    "        # Calculate metrics for each top_k\n",
    "        for top_k in top_k_list:\n",
    "            precision_scores = []\n",
    "            recall_scores = []\n",
    "            f1_scores = []\n",
    "            ndcg_scores = []\n",
    "            \n",
    "            for user_id, recommendations in all_recommendations.items():\n",
    "                relevant_items = ground_truth.get(user_id, [])\n",
    "                recommended_items = [rec['product_id'] for rec in recommendations]\n",
    "                \n",
    "                precision = evaluator.precision_at_k(recommended_items, relevant_items, top_k)\n",
    "                recall = evaluator.recall_at_k(recommended_items, relevant_items, top_k)\n",
    "                f1 = evaluator.f1_score_at_k(recommended_items, relevant_items, top_k)\n",
    "                ndcg = evaluator.ndcg_at_k(recommended_items, relevant_items, top_k)\n",
    "                \n",
    "                precision_scores.append(precision)\n",
    "                recall_scores.append(recall)\n",
    "                f1_scores.append(f1)\n",
    "                ndcg_scores.append(ndcg)\n",
    "            \n",
    "            metrics['precision'][top_k] = np.mean(precision_scores)\n",
    "            metrics['recall'][top_k] = np.mean(recall_scores)\n",
    "            metrics['f1_score'][top_k] = np.mean(f1_scores)\n",
    "            metrics['ndcg'][top_k] = np.mean(ndcg_scores)\n",
    "        \n",
    "        # Calculate MAP\n",
    "        map_score = evaluator.mean_average_precision(all_recommendations)\n",
    "        metrics['map'] = map_score\n",
    "        \n",
    "        results[k] = {\n",
    "            'metrics': metrics,\n",
    "            'recommendations': all_recommendations\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úÖ K={k} completed - F1@5: {metrics['f1_score'][5]:.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "k_values_to_test = [3, 5, 7, 10]\n",
    "top_k_values = [5, 10]\n",
    "\n",
    "evaluation_results = run_evaluation(k_values_to_test, top_k_values)\n",
    "\n",
    "print(\"\\nüéâ Full evaluation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step7_results_summary"
   },
   "outputs": [],
   "source": [
    "# Step 7b: Display Results Summary\n",
    "print(\"üìä EVALUATION RESULTS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create results table\n",
    "results_data = []\n",
    "for k in sorted(evaluation_results.keys()):\n",
    "    metrics = evaluation_results[k]['metrics']\n",
    "    results_data.append({\n",
    "        'K Value': k,\n",
    "        'Precision@5': f\"{metrics['precision'][5]:.3f}\",\n",
    "        'Recall@5': f\"{metrics['recall'][5]:.3f}\",\n",
    "        'F1-Score@5': f\"{metrics['f1_score'][5]:.3f}\",\n",
    "        'NDCG@5': f\"{metrics['ndcg'][5]:.3f}\",\n",
    "        'MAP': f\"{metrics['map']:.3f}\"\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "display(results_df)\n",
    "\n",
    "# Find best performing K\n",
    "best_k = max(evaluation_results.keys(), \n",
    "            key=lambda x: evaluation_results[x]['metrics']['f1_score'][5])\n",
    "best_f1 = evaluation_results[best_k]['metrics']['f1_score'][5]\n",
    "\n",
    "print(f\"\\nüèÜ BEST PERFORMING K VALUE: K={best_k}\")\n",
    "print(f\"   F1-Score@5: {best_f1:.3f}\")\n",
    "print(f\"   Precision@5: {evaluation_results[best_k]['metrics']['precision'][5]:.3f}\")\n",
    "print(f\"   Recall@5: {evaluation_results[best_k]['metrics']['recall'][5]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7_checkpoint"
   },
   "source": [
    "### ‚úÖ **Checkpoint 7**: Full Evaluation Complete\n",
    "Evaluasi lengkap berhasil diselesaikan! Anda dapat melihat performa algoritma untuk berbagai nilai K.\n",
    "\n",
    "Sekarang mari kita visualisasikan hasil dan lakukan analisis mendalam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8_header"
   },
   "source": [
    "## üìà Langkah 8: Visualisasi dan Analisis Hasil\n",
    "\n",
    "Mari kita buat visualisasi untuk memahami hasil evaluasi dengan lebih baik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step8_visualization"
   },
   "outputs": [],
   "source": [
    "# Step 8: Create Visualizations\n",
    "print(\"üìà Creating Performance Visualizations...\")\n",
    "\n",
    "# Prepare data for plotting\n",
    "k_values = sorted(evaluation_results.keys())\n",
    "precision_5 = [evaluation_results[k]['metrics']['precision'][5] for k in k_values]\n",
    "recall_5 = [evaluation_results[k]['metrics']['recall'][5] for k in k_values]\n",
    "f1_5 = [evaluation_results[k]['metrics']['f1_score'][5] for k in k_values]\n",
    "ndcg_5 = [evaluation_results[k]['metrics']['ndcg'][5] for k in k_values]\n",
    "map_scores = [evaluation_results[k]['metrics']['map'] for k in k_values]\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('üß™ Algorithm Performance Across Different K Values', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Precision, Recall, F1-Score\n",
    "axes[0, 0].plot(k_values, precision_5, 'o-', label='Precision@5', linewidth=2, markersize=8)\n",
    "axes[0, 0].plot(k_values, recall_5, 's-', label='Recall@5', linewidth=2, markersize=8)\n",
    "axes[0, 0].plot(k_values, f1_5, '^-', label='F1-Score@5', linewidth=2, markersize=8)\n",
    "axes[0, 0].set_xlabel('K Value')\n",
    "axes[0, 0].set_ylabel('Score')\n",
    "axes[0, 0].set_title('üìä Precision, Recall, F1-Score@5')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_xticks(k_values)\n",
    "\n",
    "# Plot 2: NDCG@5\n",
    "axes[0, 1].plot(k_values, ndcg_5, 'o-', color='purple', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xlabel('K Value')\n",
    "axes[0, 1].set_ylabel('NDCG@5 Score')\n",
    "axes[0, 1].set_title('üéØ NDCG@5 Performance')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_xticks(k_values)\n",
    "\n",
    "# Plot 3: MAP\n",
    "axes[1, 0].plot(k_values, map_scores, 'o-', color='red', linewidth=2, markersize=8)\n",
    "axes[1, 0].set_xlabel('K Value')\n",
    "axes[1, 0].set_ylabel('MAP Score')\n",
    "axes[1, 0].set_title('üé™ Mean Average Precision (MAP)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_xticks(k_values)\n",
    "\n",
    "# Plot 4: Comparison Bar Chart\n",
    "x = np.arange(len(k_values))\n",
    "width = 0.2\n",
    "\n",
    "axes[1, 1].bar(x - width, precision_5, width, label='Precision@5', alpha=0.8)\n",
    "axes[1, 1].bar(x, recall_5, width, label='Recall@5', alpha=0.8)\n",
    "axes[1, 1].bar(x + width, f1_5, width, label='F1-Score@5', alpha=0.8)\n",
    "\n",
    "axes[1, 1].set_xlabel('K Value')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "axes[1, 1].set_title('üìä Performance Comparison')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(k_values)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizations created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "step8_detailed_analysis"
   },
   "outputs": [],
   "source": [
    "# Step 8b: Detailed Performance Analysis\n",
    "print(\"üîç DETAILED PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# K-sensitivity analysis\n",
    "f1_variance = np.var(f1_5)\n",
    "f1_range = max(f1_5) - min(f1_5)\n",
    "\n",
    "print(f\"üìä K-Sensitivity Analysis:\")\n",
    "print(f\"   F1@5 Variance: {f1_variance:.6f}\")\n",
    "print(f\"   F1@5 Range: {f1_range:.3f}\")\n",
    "\n",
    "if f1_variance < 0.001:\n",
    "    sensitivity = \"Low - Algorithm is stable across K values\"\n",
    "elif f1_variance < 0.005:\n",
    "    sensitivity = \"Medium - Some variation with K values\"\n",
    "else:\n",
    "    sensitivity = \"High - Significant impact of K values\"\n",
    "\n",
    "print(f\"   Sensitivity Level: {sensitivity}\")\n",
    "\n",
    "# Best and worst performing K\n",
    "best_k_idx = np.argmax(f1_5)\n",
    "worst_k_idx = np.argmin(f1_5)\n",
    "\n",
    "print(f\"\\nüèÜ Performance Ranking:\")\n",
    "print(f\"   Best K: {k_values[best_k_idx]} (F1@5: {f1_5[best_k_idx]:.3f})\")\n",
    "print(f\"   Worst K: {k_values[worst_k_idx]} (F1@5: {f1_5[worst_k_idx]:.3f})\")\n",
    "print(f\"   Improvement: {((f1_5[best_k_idx] - f1_5[worst_k_idx]) / f1_5[worst_k_idx] * 100):.1f}%\")\n",
    "\n",
    "# Metric correlations\n",
    "print(f\"\\nüîó Metric Correlations:\")\n",
    "precision_recall_corr = np.corrcoef(precision_5, recall_5)[0, 1]\n",
    "precision_f1_corr = np.corrcoef(precision_5, f1_5)[0, 1]\n",
    "recall_f1_corr = np.corrcoef(recall_5, f1_5)[0, 1]\n",
    "\n",
    "print(f\"   Precision-Recall: {precision_recall_corr:.3f}\")\n",
    "print(f\"   Precision-F1: {precision_f1_corr:.3f}\")\n",
    "print(f\"   Recall-F1: {recall_f1_corr:.3f}\")\n",
    "\n",
    "# Recommendations based on analysis\n",
    "print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "print(f\"   üéØ Optimal K for balanced performance: K={k_values[best_k_idx]}\")\n",
    "\n",
    "if precision_5[best_k_idx] > recall_5[best_k_idx]:\n",
    "    print(f\"   üìà Algorithm favors precision over recall\")\n",
    "    print(f\"   üíº Good for applications where accuracy is more important than coverage\")\n",
    "else:\n",
    "    print(f\"   üìà Algorithm favors recall over precision\")\n",
    "    print(f\"   üíº Good for applications where coverage is more important than accuracy\")\n",
    "\n",
    "if f1_variance < 0.001:\n",
    "    print(f\"   üîí Algorithm is stable - any K value in the tested range works well\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Algorithm is K-sensitive - choose K value carefully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8_checkpoint"
   },
   "source": [
    "### ‚úÖ **Checkpoint 8**: Analysis and Visualization Complete\n",
    "Analisis mendalam berhasil diselesaikan! Anda sekarang memiliki:\n",
    "- ‚úÖ **Visualisasi performa** untuk semua metrik\n",
    "- ‚úÖ **Analisis K-sensitivity** \n",
    "- ‚úÖ **Rekomendasi nilai K optimal**\n",
    "- ‚úÖ **Insight tentang karakteristik algoritma**\n",
    "\n",
    "Mari kita buat kesimpulan akhir dan export hasil."
   ]{
    "cell_type": "markdown",
    "metadata": {
     "id": "step9_header"
    },
    "source": [
     "## üìã Langkah 9: Kesimpulan dan Rekomendasi\n",
     "\n",
     "Mari kita buat kesimpulan akhir dari evaluasi yang telah dilakukan."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
     "id": "step9_final_conclusions"
    },
    "outputs": [],
    "source": [
     "# Step 9: Generate Final Conclusions and Recommendations\n",
     "print(\"üìã KESIMPULAN AKHIR EVALUASI ALGORITMA\")\n",
     "print(\"=\" * 60)\n",
     "\n",
     "# Find overall best performing K\n",
     "best_k = max(evaluation_results.keys(), \n",
     "            key=lambda x: evaluation_results[x]['metrics']['f1_score'][5])\n",
     "best_metrics = evaluation_results[best_k]['metrics']\n",
     "\n",
     "print(f\"\\nüèÜ HASIL TERBAIK:\")\n",
     "print(f\"   üéØ Nilai K Optimal: K={best_k}\")\n",
     "print(f\"   üìä F1-Score@5: {best_metrics['f1_score'][5]:.3f}\")\n",
     "print(f\"   üìä Precision@5: {best_metrics['precision'][5]:.3f}\")\n",
     "print(f\"   üìä Recall@5: {best_metrics['recall'][5]:.3f}\")\n",
     "print(f\"   üìä NDCG@5: {best_metrics['ndcg'][5]:.3f}\")\n",
     "print(f\"   üìä MAP: {best_metrics['map']:.3f}\")\n",
     "\n",
     "# Performance interpretation\n",
     "print(f\"\\nüí° INTERPRETASI HASIL:\")\n",
     "if best_metrics['f1_score'][5] >= 0.7:\n",
     "    performance_level = \"Sangat Baik\"\n",
     "    performance_desc = \"Algoritma menunjukkan performa yang sangat baik\"\n",
     "elif best_metrics['f1_score'][5] >= 0.5:\n",
     "    performance_level = \"Baik\"\n",
     "    performance_desc = \"Algoritma menunjukkan performa yang baik dan dapat diandalkan\"\n",
     "elif best_metrics['f1_score'][5] >= 0.3:\n",
     "    performance_level = \"Cukup\"\n",
     "    performance_desc = \"Algoritma menunjukkan performa yang cukup, masih dapat ditingkatkan\"\n",
     "else:\n",
     "    performance_level = \"Perlu Perbaikan\"\n",
     "    performance_desc = \"Algoritma memerlukan perbaikan signifikan\"\n",
     "\n",
     "print(f\"   üìà Level Performa: {performance_level}\")\n",
     "print(f\"   üìù Deskripsi: {performance_desc}\")\n",
     "\n",
     "# Algorithm characteristics\n",
     "precision_recall_ratio = best_metrics['precision'][5] / best_metrics['recall'][5] if best_metrics['recall'][5] > 0 else 0\n",
     "\n",
     "print(f\"\\nüîç KARAKTERISTIK ALGORITMA:\")\n",
     "if precision_recall_ratio > 1.2:\n",
     "    print(f\"   üéØ Algoritma cenderung lebih akurat (precision-focused)\")\n",
     "    print(f\"   üíº Cocok untuk aplikasi yang mengutamakan akurasi rekomendasi\")\n",
     "elif precision_recall_ratio < 0.8:\n",
     "    print(f\"   üìä Algoritma cenderung lebih komprehensif (recall-focused)\")\n",
     "    print(f\"   üíº Cocok untuk aplikasi yang mengutamakan kelengkapan rekomendasi\")\n",
     "else:\n",
     "    print(f\"   ‚öñÔ∏è Algoritma memiliki keseimbangan yang baik antara akurasi dan kelengkapan\")\n",
     "    print(f\"   üíº Cocok untuk aplikasi umum yang membutuhkan performa seimbang\")\n",
     "\n",
     "# Stability analysis\n",
     "f1_variance = np.var([evaluation_results[k]['metrics']['f1_score'][5] for k in evaluation_results.keys()])\n",
     "print(f\"\\nüîí STABILITAS ALGORITMA:\")\n",
     "if f1_variance < 0.001:\n",
     "    print(f\"   ‚úÖ Sangat stabil - performa konsisten di berbagai nilai K\")\n",
     "    print(f\"   üéØ Rekomendasi: Nilai K apa pun dalam rentang yang diuji dapat digunakan\")\n",
     "elif f1_variance < 0.005:\n",
     "    print(f\"   ‚ö†Ô∏è Cukup stabil - ada sedikit variasi performa\")\n",
     "    print(f\"   üéØ Rekomendasi: Gunakan K={best_k} untuk hasil optimal\")\n",
     "else:\n",
     "    print(f\"   ‚ùó Sensitif terhadap K - performa bervariasi signifikan\")\n",
     "    print(f\"   üéØ Rekomendasi: Hati-hati dalam memilih nilai K, gunakan K={best_k}\")\n",
     "\n",
     "print(f\"\\n\" + \"=\" * 60)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
     "id": "step9_implementation_guide"
    },
    "outputs": [],
    "source": [
     "# Step 9b: Implementation Guidelines\n",
     "print(\"üöÄ PANDUAN IMPLEMENTASI\")\n",
     "print(\"=\" * 40)\n",
     "\n",
     "print(f\"\\nüìã REKOMENDASI IMPLEMENTASI:\")\n",
     "print(f\"\\n1. üéØ NILAI K YANG DISARANKAN:\")\n",
     "print(f\"   ‚Ä¢ Untuk produksi: K={best_k}\")\n",
     "print(f\"   ‚Ä¢ Untuk akurasi tinggi: K=3\")\n",
     "print(f\"   ‚Ä¢ Untuk coverage tinggi: K=7-10\")\n",
     "\n",
     "print(f\"\\n2. üìä MONITORING METRIK:\")\n",
     "print(f\"   ‚Ä¢ Precision@5: Target ‚â• {best_metrics['precision'][5]:.3f}\")\n",
     "print(f\"   ‚Ä¢ Recall@5: Target ‚â• {best_metrics['recall'][5]:.3f}\")\n",
     "print(f\"   ‚Ä¢ F1-Score@5: Target ‚â• {best_metrics['f1_score'][5]:.3f}\")\n",
     "\n",
     "print(f\"\\n3. üîß PARAMETER TUNING:\")\n",
     "print(f\"   ‚Ä¢ Mulai dengan K={best_k}\")\n",
     "print(f\"   ‚Ä¢ Monitor performa secara berkala\")\n",
     "print(f\"   ‚Ä¢ Sesuaikan K berdasarkan feedback pengguna\")\n",
     "\n",
     "print(f\"\\n4. üìà OPTIMISASI LANJUTAN:\")\n",
     "print(f\"   ‚Ä¢ Pertimbangkan feature engineering tambahan\")\n",
     "print(f\"   ‚Ä¢ Eksperimen dengan bobot yang berbeda\")\n",
     "print(f\"   ‚Ä¢ Implementasi A/B testing untuk validasi\")\n",
     "\n",
     "print(f\"\\n5. ‚ö†Ô∏è PERTIMBANGAN KHUSUS:\")\n",
     "print(f\"   ‚Ä¢ Dataset sintetis - validasi dengan data real diperlukan\")\n",
     "print(f\"   ‚Ä¢ Pertimbangkan cold start problem untuk user baru\")\n",
     "print(f\"   ‚Ä¢ Implementasi fallback mechanism\")\n",
     "\n",
     "print(f\"\\n\" + \"=\" * 40)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {
     "id": "step9_checkpoint"
    },
    "source": [
     "### ‚úÖ **Checkpoint 9**: Evaluation Complete!\n",
     "\n",
     "üéâ **Selamat!** Anda telah berhasil menyelesaikan evaluasi algoritma rekomendasi skincare secara lengkap!\n",
     "\n",
     "## üìä **Ringkasan Pencapaian:**\n",
     "- ‚úÖ **Environment Setup** - Library dan dependencies siap\n",
     "- ‚úÖ **Data Generation** - Dataset sintetis 50 produk & 20 pengguna\n",
     "- ‚úÖ **Algorithm Implementation** - Hybrid CBF+KNN system\n",
     "- ‚úÖ **Ground Truth Creation** - Data referensi untuk evaluasi\n",
     "- ‚úÖ **Metrics Implementation** - Precision, Recall, F1, NDCG, MAP\n",
     "- ‚úÖ **Full Evaluation** - Testing dengan berbagai nilai K\n",
     "- ‚úÖ **Visualization & Analysis** - Grafik dan insight mendalam\n",
     "- ‚úÖ **Conclusions & Recommendations** - Panduan implementasi\n",
     "\n",
     "## üéØ **Hasil Utama:**\n",
     "- **Nilai K optimal** telah diidentifikasi\n",
     "- **Karakteristik algoritma** telah dianalisis\n",
     "- **Panduan implementasi** telah disediakan\n",
     "- **Metrik performa** telah dievaluasi secara komprehensif\n",
     "\n",
     "## üöÄ **Langkah Selanjutnya:**\n",
     "1. **Implementasi** sistem dengan nilai K yang direkomendasikan\n",
     "2. **Testing** dengan data real pengguna\n",
     "3. **Monitoring** performa di production\n",
     "4. **Iterasi** berdasarkan feedback pengguna\n",
     "\n",
     "---\n",
     "**Terima kasih telah mengikuti evaluasi ini! üôè**"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {
     "id": "appendix_header"
    },
    "source": [
     "## üìö Appendix: Informasi Tambahan\n",
     "\n",
     "### üîç **Penjelasan Metrik Evaluasi:**\n",
     "\n",
     "**Precision@K**: Mengukur proporsi item relevan dalam K rekomendasi teratas\n",
     "- Formula: `Relevant items in top-K / K`\n",
     "- Interpretasi: Seberapa akurat rekomendasi yang diberikan\n",
     "\n",
     "**Recall@K**: Mengukur proporsi item relevan yang berhasil ditangkap dalam K rekomendasi\n",
     "- Formula: `Relevant items in top-K / Total relevant items`\n",
     "- Interpretasi: Seberapa lengkap rekomendasi menangkap item relevan\n",
     "\n",
     "**F1-Score@K**: Harmonic mean dari Precision dan Recall\n",
     "- Formula: `2 * (Precision * Recall) / (Precision + Recall)`\n",
     "- Interpretasi: Keseimbangan antara akurasi dan kelengkapan\n",
     "\n",
     "**NDCG@K**: Normalized Discounted Cumulative Gain\n",
     "- Mengukur kualitas ranking dengan mempertimbangkan posisi\n",
     "- Interpretasi: Seberapa baik urutan rekomendasi\n",
     "\n",
     "**MAP**: Mean Average Precision\n",
     "- Rata-rata dari Average Precision semua pengguna\n",
     "- Interpretasi: Performa keseluruhan sistem rekomendasi\n",
     "\n",
     "### ü§ñ **Cara Kerja Algoritma Hybrid CBF+KNN:**\n",
     "\n",
     "1. **Content-Based Filtering**: Menghitung similarity antara profil pengguna dan produk menggunakan TF-IDF\n",
     "2. **K-Nearest Neighbors**: Mencari K pengguna terdekat berdasarkan kesamaan preferensi\n",
     "3. **Hybrid Scoring**: Menggabungkan skor CBF dengan boost dari KNN\n",
     "4. **Ranking**: Mengurutkan produk berdasarkan skor akhir\n",
     "\n",
     "### üìä **Interpretasi Nilai K:**\n",
     "\n",
     "- **K kecil (3-5)**: Lebih selektif, fokus pada pengguna yang sangat mirip\n",
     "- **K sedang (5-7)**: Keseimbangan antara selektivitas dan diversitas\n",
     "- **K besar (7-10)**: Lebih inklusif, mempertimbangkan lebih banyak pengguna\n",
     "\n",
     "### ‚ö†Ô∏è **Limitasi Evaluasi:**\n",
     "\n",
     "1. **Dataset Sintetis**: Hasil mungkin berbeda dengan data real\n",
     "2. **Ground Truth Sederhana**: Menggunakan aturan matching yang basic\n",
     "3. **Skala Kecil**: 50 produk dan 20 pengguna untuk demo\n",
     "4. **Tanpa Temporal Factor**: Tidak mempertimbangkan perubahan preferensi waktu\n",
     "\n",
     "### üîß **Tips Implementasi Production:**\n",
     "\n",
     "1. **Scalability**: Gunakan approximate nearest neighbor untuk dataset besar\n",
     "2. **Real-time**: Implementasi caching untuk response time yang cepat\n",
     "3. **Cold Start**: Siapkan strategi untuk pengguna/produk baru\n",
     "4. **Feedback Loop**: Implementasi implicit/explicit feedback collection\n",
     "5. **A/B Testing**: Validasi performa dengan eksperimen terkontrol"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.8.0"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 4
 }